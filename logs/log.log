15-11-2018 11:25:29.794 [main] INFO  c.s.c.ChallengeCreatorApplication.logStarting - Starting ChallengeCreatorApplication on cgi-Latitude-E5440 with PID 11679 (/home/cgi/challenge-creator/target/classes started by cgi in /home/cgi/challenge-creator)
15-11-2018 11:25:29.843 [main] INFO  c.s.c.ChallengeCreatorApplication.logStartupProfileInfo - No active profile set, falling back to default profiles: default
15-11-2018 11:25:31.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate.registerRepositoriesIn - Bootstrapping Spring Data repositories in DEFAULT mode.
15-11-2018 11:25:31.753 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate.registerRepositoriesIn - Finished Spring Data repository scanning in 109ms. Found 5 repository interfaces.
15-11-2018 11:25:32.770 [main] INFO  o.s.b.w.e.tomcat.TomcatWebServer.initialize - Tomcat initialized with port(s): 8080 (http)
15-11-2018 11:25:32.802 [main] INFO  o.a.catalina.core.StandardService.log - Starting service [Tomcat]
15-11-2018 11:25:32.803 [main] INFO  o.a.catalina.core.StandardEngine.log - Starting Servlet Engine: Apache Tomcat/9.0.12
15-11-2018 11:25:32.817 [main] INFO  o.a.c.core.AprLifecycleListener.log - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib]
15-11-2018 11:25:32.981 [main] INFO  o.a.c.c.C.[Tomcat].[localhost].[/].log - Initializing Spring embedded WebApplicationContext
15-11-2018 11:25:33.033 [main] INFO  o.s.b.w.s.ServletRegistrationBean.addRegistration - Servlet dispatcherServlet mapped to [/]
15-11-2018 11:25:33.039 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'characterEncodingFilter' to: [/*]
15-11-2018 11:25:33.040 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
15-11-2018 11:25:33.040 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'formContentFilter' to: [/*]
15-11-2018 11:25:33.040 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'requestContextFilter' to: [/*]
15-11-2018 11:25:33.602 [main] INFO  org.mongodb.driver.cluster.info - Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
15-11-2018 11:25:33.763 [cluster-ClusterId{value='5bed0a5532f17c2d9f19d400', description='null'}-localhost:27017] INFO  org.mongodb.driver.connection.info - Opened connection [connectionId{localValue:1, serverValue:1}] to localhost:27017
15-11-2018 11:25:33.772 [cluster-ClusterId{value='5bed0a5532f17c2d9f19d400', description='null'}-localhost:27017] INFO  org.mongodb.driver.cluster.info - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 3]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=3358732}
15-11-2018 11:25:34.588 [main] INFO  o.s.s.c.ThreadPoolTaskExecutor.initialize - Initializing ExecutorService 'applicationTaskExecutor'
15-11-2018 11:25:34.964 [main] INFO  o.s.b.w.e.tomcat.TomcatWebServer.start - Tomcat started on port(s): 8080 (http) with context path ''
15-11-2018 11:25:34.977 [main] INFO  c.s.c.ChallengeCreatorApplication.logStarted - Started ChallengeCreatorApplication in 6.512 seconds (JVM running for 8.675)
15-11-2018 11:27:45.467 [http-nio-8080-exec-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/].log - Initializing Spring DispatcherServlet 'dispatcherServlet'
15-11-2018 11:27:45.748 [http-nio-8080-exec-1] INFO  org.mongodb.driver.connection.info - Opened connection [connectionId{localValue:2, serverValue:3}] to localhost:27017
15-11-2018 11:28:28.107 [http-nio-8080-exec-3] ERROR o.a.c.c.C.[.[.[.[dispatcherServlet].log - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.util.NoSuchElementException: No value present] with root cause
java.util.NoSuchElementException: No value present
	at java.base/java.util.Optional.get(Optional.java:148)
	at com.stackroute.challengecreator.controller.ChallengeController.getChallengeById(ChallengeController.java:82)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:215)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:142)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:800)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1038)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:942)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:998)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:890)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:634)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:875)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:741)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:92)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:490)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:408)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:770)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1415)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.base/java.lang.Thread.run(Thread.java:844)
15-11-2018 11:29:19.238 [http-nio-8080-exec-4] ERROR o.a.c.c.C.[.[.[.[dispatcherServlet].log - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is com.stackroute.challengecreator.exceptions.ChallengeAlreadyExistsException: challenge already exists] with root cause
com.stackroute.challengecreator.exceptions.ChallengeAlreadyExistsException: challenge already exists
	at com.stackroute.challengecreator.service.ChallengeServiceImpl.addChallengeObjL1(ChallengeServiceImpl.java:112)
	at com.stackroute.challengecreator.controller.ChallengeController.saveChallenge(ChallengeController.java:35)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:215)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:142)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:800)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1038)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:942)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:998)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:901)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:660)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:875)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:741)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:92)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:490)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:408)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:770)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1415)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.base/java.lang.Thread.run(Thread.java:844)
15-11-2018 11:30:16.494 [Thread-2] INFO  o.s.s.c.ThreadPoolTaskExecutor.shutdown - Shutting down ExecutorService 'applicationTaskExecutor'
15-11-2018 11:30:16.497 [Thread-2] INFO  org.mongodb.driver.connection.info - Closed connection [connectionId{localValue:2, serverValue:3}] to localhost:27017 because the pool has been closed.
15-11-2018 12:14:38.798 [main] INFO  c.s.c.ChallengeCreatorApplication.logStarting - Starting ChallengeCreatorApplication on cgi-Latitude-E5440 with PID 30939 (/home/cgi/challenge-creator/target/classes started by cgi in /home/cgi/challenge-creator)
15-11-2018 12:14:38.807 [main] INFO  c.s.c.ChallengeCreatorApplication.logStartupProfileInfo - No active profile set, falling back to default profiles: default
15-11-2018 12:14:40.317 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate.registerRepositoriesIn - Bootstrapping Spring Data repositories in DEFAULT mode.
15-11-2018 12:14:40.444 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate.registerRepositoriesIn - Finished Spring Data repository scanning in 118ms. Found 5 repository interfaces.
15-11-2018 12:14:40.974 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker.postProcessAfterInitialization - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$e6b19509] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
15-11-2018 12:14:41.608 [main] INFO  o.s.b.w.e.tomcat.TomcatWebServer.initialize - Tomcat initialized with port(s): 8080 (http)
15-11-2018 12:14:41.642 [main] INFO  o.a.catalina.core.StandardService.log - Starting service [Tomcat]
15-11-2018 12:14:41.642 [main] INFO  o.a.catalina.core.StandardEngine.log - Starting Servlet Engine: Apache Tomcat/9.0.12
15-11-2018 12:14:41.657 [main] INFO  o.a.c.core.AprLifecycleListener.log - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib]
15-11-2018 12:14:41.773 [main] INFO  o.a.c.c.C.[Tomcat].[localhost].[/].log - Initializing Spring embedded WebApplicationContext
15-11-2018 12:14:41.811 [main] INFO  o.s.b.w.s.ServletRegistrationBean.addRegistration - Servlet dispatcherServlet mapped to [/]
15-11-2018 12:14:41.817 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'characterEncodingFilter' to: [/*]
15-11-2018 12:14:41.818 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
15-11-2018 12:14:41.819 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'formContentFilter' to: [/*]
15-11-2018 12:14:41.819 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'requestContextFilter' to: [/*]
15-11-2018 12:14:42.236 [main] INFO  org.mongodb.driver.cluster.info - Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
15-11-2018 12:14:42.305 [cluster-ClusterId{value='5bed15da85151f78dbdb4587', description='null'}-localhost:27017] INFO  org.mongodb.driver.connection.info - Opened connection [connectionId{localValue:1, serverValue:4}] to localhost:27017
15-11-2018 12:14:42.311 [cluster-ClusterId{value='5bed15da85151f78dbdb4587', description='null'}-localhost:27017] INFO  org.mongodb.driver.cluster.info - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 3]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=3361747}
15-11-2018 12:14:43.156 [main] INFO  o.s.s.c.ThreadPoolTaskExecutor.initialize - Initializing ExecutorService 'applicationTaskExecutor'
15-11-2018 12:14:43.541 [main] INFO  o.s.b.w.e.tomcat.TomcatWebServer.start - Tomcat started on port(s): 8080 (http) with context path ''
15-11-2018 12:14:43.544 [main] INFO  c.s.c.ChallengeCreatorApplication.logStarted - Started ChallengeCreatorApplication in 5.771 seconds (JVM running for 6.764)
15-11-2018 12:16:40.782 [Thread-2] INFO  o.s.s.c.ThreadPoolTaskExecutor.shutdown - Shutting down ExecutorService 'applicationTaskExecutor'
15-11-2018 12:16:45.684 [main] INFO  c.s.c.ChallengeCreatorApplication.logStarting - Starting ChallengeCreatorApplication on cgi-Latitude-E5440 with PID 31886 (/home/cgi/challenge-creator/target/classes started by cgi in /home/cgi/challenge-creator)
15-11-2018 12:16:45.704 [main] INFO  c.s.c.ChallengeCreatorApplication.logStartupProfileInfo - No active profile set, falling back to default profiles: default
15-11-2018 12:16:47.181 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate.registerRepositoriesIn - Bootstrapping Spring Data repositories in DEFAULT mode.
15-11-2018 12:16:47.273 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate.registerRepositoriesIn - Finished Spring Data repository scanning in 85ms. Found 5 repository interfaces.
15-11-2018 12:16:47.659 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker.postProcessAfterInitialization - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$30eccc0d] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
15-11-2018 12:16:48.197 [main] INFO  o.s.b.w.e.tomcat.TomcatWebServer.initialize - Tomcat initialized with port(s): 8080 (http)
15-11-2018 12:16:48.242 [main] INFO  o.a.catalina.core.StandardService.log - Starting service [Tomcat]
15-11-2018 12:16:48.243 [main] INFO  o.a.catalina.core.StandardEngine.log - Starting Servlet Engine: Apache Tomcat/9.0.12
15-11-2018 12:16:48.258 [main] INFO  o.a.c.core.AprLifecycleListener.log - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib]
15-11-2018 12:16:48.371 [main] INFO  o.a.c.c.C.[Tomcat].[localhost].[/].log - Initializing Spring embedded WebApplicationContext
15-11-2018 12:16:48.414 [main] INFO  o.s.b.w.s.ServletRegistrationBean.addRegistration - Servlet dispatcherServlet mapped to [/]
15-11-2018 12:16:48.420 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'characterEncodingFilter' to: [/*]
15-11-2018 12:16:48.421 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
15-11-2018 12:16:48.422 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'formContentFilter' to: [/*]
15-11-2018 12:16:48.423 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'requestContextFilter' to: [/*]
15-11-2018 12:16:48.765 [main] INFO  org.mongodb.driver.cluster.info - Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
15-11-2018 12:16:48.861 [cluster-ClusterId{value='5bed16580311de7c8e8c645b', description='null'}-localhost:27017] INFO  org.mongodb.driver.connection.info - Opened connection [connectionId{localValue:1, serverValue:5}] to localhost:27017
15-11-2018 12:16:48.869 [cluster-ClusterId{value='5bed16580311de7c8e8c645b', description='null'}-localhost:27017] INFO  org.mongodb.driver.cluster.info - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 3]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=3667037}
15-11-2018 12:16:49.373 [main] WARN  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext.refresh - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'challengeController': Unsatisfied dependency expressed through field 'challengeResource'; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'com.stackroute.challengecreator.kafka.producer.ChallengeResource' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)}
15-11-2018 12:16:49.381 [main] INFO  o.a.catalina.core.StandardService.log - Stopping service [Tomcat]
15-11-2018 12:16:49.409 [main] INFO  o.s.b.a.l.ConditionEvaluationReportLoggingListener.logMessage - 

Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
15-11-2018 12:16:49.627 [main] ERROR o.s.b.d.LoggingFailureAnalysisReporter.report - 

***************************
APPLICATION FAILED TO START
***************************

Description:

Field challengeResource in com.stackroute.challengecreator.controller.ChallengeController required a bean of type 'com.stackroute.challengecreator.kafka.producer.ChallengeResource' that could not be found.

The injection point has the following annotations:
	- @org.springframework.beans.factory.annotation.Autowired(required=true)


Action:

Consider defining a bean of type 'com.stackroute.challengecreator.kafka.producer.ChallengeResource' in your configuration.

15-11-2018 12:25:21.968 [main] INFO  c.s.c.ChallengeCreatorApplication.logStarting - Starting ChallengeCreatorApplication on cgi-Latitude-E5440 with PID 3339 (/home/cgi/challenge-creator/target/classes started by cgi in /home/cgi/challenge-creator)
15-11-2018 12:25:21.974 [main] INFO  c.s.c.ChallengeCreatorApplication.logStartupProfileInfo - No active profile set, falling back to default profiles: default
15-11-2018 12:25:23.594 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate.registerRepositoriesIn - Bootstrapping Spring Data repositories in DEFAULT mode.
15-11-2018 12:25:23.694 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate.registerRepositoriesIn - Finished Spring Data repository scanning in 93ms. Found 5 repository interfaces.
15-11-2018 12:25:24.062 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker.postProcessAfterInitialization - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$5c4b4bc1] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
15-11-2018 12:25:24.493 [main] INFO  o.s.b.w.e.tomcat.TomcatWebServer.initialize - Tomcat initialized with port(s): 8080 (http)
15-11-2018 12:25:24.520 [main] INFO  o.a.catalina.core.StandardService.log - Starting service [Tomcat]
15-11-2018 12:25:24.521 [main] INFO  o.a.catalina.core.StandardEngine.log - Starting Servlet Engine: Apache Tomcat/9.0.12
15-11-2018 12:25:24.533 [main] INFO  o.a.c.core.AprLifecycleListener.log - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib]
15-11-2018 12:25:24.635 [main] INFO  o.a.c.c.C.[Tomcat].[localhost].[/].log - Initializing Spring embedded WebApplicationContext
15-11-2018 12:25:24.675 [main] INFO  o.s.b.w.s.ServletRegistrationBean.addRegistration - Servlet dispatcherServlet mapped to [/]
15-11-2018 12:25:24.680 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'characterEncodingFilter' to: [/*]
15-11-2018 12:25:24.680 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
15-11-2018 12:25:24.680 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'formContentFilter' to: [/*]
15-11-2018 12:25:24.681 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'requestContextFilter' to: [/*]
15-11-2018 12:25:25.053 [main] INFO  org.mongodb.driver.cluster.info - Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
15-11-2018 12:25:25.115 [cluster-ClusterId{value='5bed185deca50d0d0bead72d', description='null'}-localhost:27017] INFO  org.mongodb.driver.connection.info - Opened connection [connectionId{localValue:1, serverValue:6}] to localhost:27017
15-11-2018 12:25:25.130 [cluster-ClusterId{value='5bed185deca50d0d0bead72d', description='null'}-localhost:27017] INFO  org.mongodb.driver.cluster.info - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 3]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=3360183}
15-11-2018 12:25:25.894 [main] INFO  o.s.s.c.ThreadPoolTaskExecutor.initialize - Initializing ExecutorService 'applicationTaskExecutor'
15-11-2018 12:25:26.317 [main] INFO  o.s.b.w.e.tomcat.TomcatWebServer.start - Tomcat started on port(s): 8080 (http) with context path ''
15-11-2018 12:25:26.322 [main] INFO  c.s.c.ChallengeCreatorApplication.logStarted - Started ChallengeCreatorApplication in 5.18 seconds (JVM running for 5.945)
15-11-2018 12:25:52.869 [Thread-2] INFO  o.s.s.c.ThreadPoolTaskExecutor.shutdown - Shutting down ExecutorService 'applicationTaskExecutor'
15-11-2018 12:25:58.849 [main] INFO  c.s.c.ChallengeCreatorApplication.logStarting - Starting ChallengeCreatorApplication on cgi-Latitude-E5440 with PID 3721 (/home/cgi/challenge-creator/target/classes started by cgi in /home/cgi/challenge-creator)
15-11-2018 12:25:58.858 [main] INFO  c.s.c.ChallengeCreatorApplication.logStartupProfileInfo - No active profile set, falling back to default profiles: default
15-11-2018 12:26:00.394 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate.registerRepositoriesIn - Bootstrapping Spring Data repositories in DEFAULT mode.
15-11-2018 12:26:00.491 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate.registerRepositoriesIn - Finished Spring Data repository scanning in 90ms. Found 5 repository interfaces.
15-11-2018 12:26:00.911 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker.postProcessAfterInitialization - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$e42d9501] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
15-11-2018 12:26:01.464 [main] INFO  o.s.b.w.e.tomcat.TomcatWebServer.initialize - Tomcat initialized with port(s): 8080 (http)
15-11-2018 12:26:01.497 [main] INFO  o.a.catalina.core.StandardService.log - Starting service [Tomcat]
15-11-2018 12:26:01.498 [main] INFO  o.a.catalina.core.StandardEngine.log - Starting Servlet Engine: Apache Tomcat/9.0.12
15-11-2018 12:26:01.512 [main] INFO  o.a.c.core.AprLifecycleListener.log - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib]
15-11-2018 12:26:01.634 [main] INFO  o.a.c.c.C.[Tomcat].[localhost].[/].log - Initializing Spring embedded WebApplicationContext
15-11-2018 12:26:01.673 [main] INFO  o.s.b.w.s.ServletRegistrationBean.addRegistration - Servlet dispatcherServlet mapped to [/]
15-11-2018 12:26:01.681 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'characterEncodingFilter' to: [/*]
15-11-2018 12:26:01.682 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
15-11-2018 12:26:01.683 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'formContentFilter' to: [/*]
15-11-2018 12:26:01.683 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'requestContextFilter' to: [/*]
15-11-2018 12:26:02.013 [main] INFO  org.mongodb.driver.cluster.info - Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
15-11-2018 12:26:02.113 [cluster-ClusterId{value='5bed1882f7d7300e896d8834', description='null'}-localhost:27017] INFO  org.mongodb.driver.connection.info - Opened connection [connectionId{localValue:1, serverValue:7}] to localhost:27017
15-11-2018 12:26:02.125 [cluster-ClusterId{value='5bed1882f7d7300e896d8834', description='null'}-localhost:27017] INFO  org.mongodb.driver.cluster.info - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 3]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=3221751}
15-11-2018 12:26:02.558 [main] WARN  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext.refresh - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'challengeController': Unsatisfied dependency expressed through field 'challengeResource'; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'com.stackroute.challengecreator.kafka.producer.ChallengeResource' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)}
15-11-2018 12:26:02.565 [main] INFO  o.a.catalina.core.StandardService.log - Stopping service [Tomcat]
15-11-2018 12:26:02.586 [main] INFO  o.s.b.a.l.ConditionEvaluationReportLoggingListener.logMessage - 

Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
15-11-2018 12:26:02.755 [main] ERROR o.s.b.d.LoggingFailureAnalysisReporter.report - 

***************************
APPLICATION FAILED TO START
***************************

Description:

Field challengeResource in com.stackroute.challengecreator.controller.ChallengeController required a bean of type 'com.stackroute.challengecreator.kafka.producer.ChallengeResource' that could not be found.

The injection point has the following annotations:
	- @org.springframework.beans.factory.annotation.Autowired(required=true)


Action:

Consider defining a bean of type 'com.stackroute.challengecreator.kafka.producer.ChallengeResource' in your configuration.

15-11-2018 12:26:55.787 [main] INFO  c.s.c.ChallengeCreatorApplication.logStarting - Starting ChallengeCreatorApplication on cgi-Latitude-E5440 with PID 4084 (/home/cgi/challenge-creator/target/classes started by cgi in /home/cgi/challenge-creator)
15-11-2018 12:26:55.798 [main] INFO  c.s.c.ChallengeCreatorApplication.logStartupProfileInfo - No active profile set, falling back to default profiles: default
15-11-2018 12:26:57.357 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate.registerRepositoriesIn - Bootstrapping Spring Data repositories in DEFAULT mode.
15-11-2018 12:26:57.459 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate.registerRepositoriesIn - Finished Spring Data repository scanning in 95ms. Found 5 repository interfaces.
15-11-2018 12:26:57.874 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker.postProcessAfterInitialization - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$219c526a] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
15-11-2018 12:26:58.434 [main] INFO  o.s.b.w.e.tomcat.TomcatWebServer.initialize - Tomcat initialized with port(s): 8080 (http)
15-11-2018 12:26:58.469 [main] INFO  o.a.catalina.core.StandardService.log - Starting service [Tomcat]
15-11-2018 12:26:58.470 [main] INFO  o.a.catalina.core.StandardEngine.log - Starting Servlet Engine: Apache Tomcat/9.0.12
15-11-2018 12:26:58.485 [main] INFO  o.a.c.core.AprLifecycleListener.log - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib]
15-11-2018 12:26:58.608 [main] INFO  o.a.c.c.C.[Tomcat].[localhost].[/].log - Initializing Spring embedded WebApplicationContext
15-11-2018 12:26:58.658 [main] INFO  o.s.b.w.s.ServletRegistrationBean.addRegistration - Servlet dispatcherServlet mapped to [/]
15-11-2018 12:26:58.665 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'characterEncodingFilter' to: [/*]
15-11-2018 12:26:58.666 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
15-11-2018 12:26:58.667 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'formContentFilter' to: [/*]
15-11-2018 12:26:58.667 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'requestContextFilter' to: [/*]
15-11-2018 12:26:58.966 [main] INFO  org.mongodb.driver.cluster.info - Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
15-11-2018 12:26:59.050 [cluster-ClusterId{value='5bed18bab7c0050ff408593d', description='null'}-localhost:27017] INFO  org.mongodb.driver.connection.info - Opened connection [connectionId{localValue:1, serverValue:8}] to localhost:27017
15-11-2018 12:26:59.062 [cluster-ClusterId{value='5bed18bab7c0050ff408593d', description='null'}-localhost:27017] INFO  org.mongodb.driver.cluster.info - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 3]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=3376745}
15-11-2018 12:26:59.865 [main] INFO  o.s.s.c.ThreadPoolTaskExecutor.initialize - Initializing ExecutorService 'applicationTaskExecutor'
15-11-2018 12:27:00.273 [main] INFO  o.s.b.w.e.tomcat.TomcatWebServer.start - Tomcat started on port(s): 8080 (http) with context path ''
15-11-2018 12:27:00.277 [main] INFO  c.s.c.ChallengeCreatorApplication.logStarted - Started ChallengeCreatorApplication in 5.39 seconds (JVM running for 6.177)
15-11-2018 12:27:39.462 [http-nio-8080-exec-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/].log - Initializing Spring DispatcherServlet 'dispatcherServlet'
15-11-2018 12:27:39.740 [http-nio-8080-exec-1] INFO  org.mongodb.driver.connection.info - Opened connection [connectionId{localValue:2, serverValue:9}] to localhost:27017
15-11-2018 12:27:39.818 [http-nio-8080-exec-1] ERROR o.a.c.c.C.[.[.[.[dispatcherServlet].log - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is com.stackroute.challengecreator.exceptions.ChallengeAlreadyExistsException: challenge already exists] with root cause
com.stackroute.challengecreator.exceptions.ChallengeAlreadyExistsException: challenge already exists
	at com.stackroute.challengecreator.service.ChallengeServiceImpl.addChallengeObjL1(ChallengeServiceImpl.java:112)
	at com.stackroute.challengecreator.controller.ChallengeController.saveChallenge(ChallengeController.java:38)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:215)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:142)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:800)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1038)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:942)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:998)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:901)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:660)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:875)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:741)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:92)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:490)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:408)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:770)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1415)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.base/java.lang.Thread.run(Thread.java:844)
15-11-2018 12:27:59.724 [http-nio-8080-exec-3] ERROR o.a.c.c.C.[.[.[.[dispatcherServlet].log - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is com.stackroute.challengecreator.exceptions.ChallengeAlreadyExistsException: challenge already exists] with root cause
com.stackroute.challengecreator.exceptions.ChallengeAlreadyExistsException: challenge already exists
	at com.stackroute.challengecreator.service.ChallengeServiceImpl.addChallengeObjL1(ChallengeServiceImpl.java:112)
	at com.stackroute.challengecreator.controller.ChallengeController.saveChallenge(ChallengeController.java:38)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:215)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:142)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:800)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1038)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:942)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:998)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:901)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:660)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:875)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:741)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:92)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:490)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:408)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:770)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1415)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.base/java.lang.Thread.run(Thread.java:844)
15-11-2018 12:28:17.203 [http-nio-8080-exec-2] INFO  o.a.k.c.producer.ProducerConfig.logAll - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [172.23.239.131:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

15-11-2018 12:28:17.291 [http-nio-8080-exec-2] INFO  o.a.kafka.common.utils.AppInfoParser.<init> - Kafka version : 2.0.0
15-11-2018 12:28:17.292 [http-nio-8080-exec-2] INFO  o.a.kafka.common.utils.AppInfoParser.<init> - Kafka commitId : 3402a8361b734732
15-11-2018 12:28:17.525 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata.update - Cluster ID: P9qNm97PQxmUwOTGinTT9g
15-11-2018 12:36:09.576 [Thread-2] INFO  o.s.s.c.ThreadPoolTaskExecutor.shutdown - Shutting down ExecutorService 'applicationTaskExecutor'
15-11-2018 12:36:09.577 [Thread-2] INFO  o.a.k.clients.producer.KafkaProducer.close - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
15-11-2018 12:36:09.583 [Thread-2] INFO  org.mongodb.driver.connection.info - Closed connection [connectionId{localValue:2, serverValue:9}] to localhost:27017 because the pool has been closed.
15-11-2018 12:36:18.524 [main] INFO  c.s.c.ChallengeCreatorApplication.logStarting - Starting ChallengeCreatorApplication on cgi-Latitude-E5440 with PID 7871 (/home/cgi/challenge-creator/target/classes started by cgi in /home/cgi/challenge-creator)
15-11-2018 12:36:18.548 [main] INFO  c.s.c.ChallengeCreatorApplication.logStartupProfileInfo - No active profile set, falling back to default profiles: default
15-11-2018 12:36:21.931 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate.registerRepositoriesIn - Bootstrapping Spring Data repositories in DEFAULT mode.
15-11-2018 12:36:22.161 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate.registerRepositoriesIn - Finished Spring Data repository scanning in 213ms. Found 5 repository interfaces.
15-11-2018 12:36:22.999 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker.postProcessAfterInitialization - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$4a10042c] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
15-11-2018 12:36:24.301 [main] INFO  o.s.b.w.e.tomcat.TomcatWebServer.initialize - Tomcat initialized with port(s): 8080 (http)
15-11-2018 12:36:24.395 [main] INFO  o.a.catalina.core.StandardService.log - Starting service [Tomcat]
15-11-2018 12:36:24.397 [main] INFO  o.a.catalina.core.StandardEngine.log - Starting Servlet Engine: Apache Tomcat/9.0.12
15-11-2018 12:36:24.433 [main] INFO  o.a.c.core.AprLifecycleListener.log - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib]
15-11-2018 12:36:24.722 [main] INFO  o.a.c.c.C.[Tomcat].[localhost].[/].log - Initializing Spring embedded WebApplicationContext
15-11-2018 12:36:24.819 [main] INFO  o.s.b.w.s.ServletRegistrationBean.addRegistration - Servlet dispatcherServlet mapped to [/]
15-11-2018 12:36:24.831 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'characterEncodingFilter' to: [/*]
15-11-2018 12:36:24.832 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
15-11-2018 12:36:24.832 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'formContentFilter' to: [/*]
15-11-2018 12:36:24.833 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'requestContextFilter' to: [/*]
15-11-2018 12:36:25.482 [main] INFO  org.mongodb.driver.cluster.info - Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
15-11-2018 12:36:25.696 [cluster-ClusterId{value='5bed1af16d9b061ebf3db9bc', description='null'}-localhost:27017] INFO  org.mongodb.driver.connection.info - Opened connection [connectionId{localValue:1, serverValue:10}] to localhost:27017
15-11-2018 12:36:25.728 [cluster-ClusterId{value='5bed1af16d9b061ebf3db9bc', description='null'}-localhost:27017] INFO  org.mongodb.driver.cluster.info - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 3]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=3483610}
15-11-2018 12:36:26.707 [main] INFO  o.s.s.c.ThreadPoolTaskExecutor.initialize - Initializing ExecutorService 'applicationTaskExecutor'
15-11-2018 12:36:26.986 [main] INFO  o.a.k.c.consumer.ConsumerConfig.logAll - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [172.23.239.131:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.BytesDeserializer

15-11-2018 12:36:27.050 [main] INFO  o.a.kafka.common.utils.AppInfoParser.<init> - Kafka version : 2.0.0
15-11-2018 12:36:27.051 [main] INFO  o.a.kafka.common.utils.AppInfoParser.<init> - Kafka commitId : 3402a8361b734732
15-11-2018 12:36:27.255 [main] INFO  org.apache.kafka.clients.Metadata.update - Cluster ID: P9qNm97PQxmUwOTGinTT9g
15-11-2018 12:36:27.294 [main] INFO  o.a.k.c.consumer.ConsumerConfig.logAll - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [172.23.239.131:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.BytesDeserializer

15-11-2018 12:36:27.302 [main] INFO  o.a.kafka.common.utils.AppInfoParser.<init> - Kafka version : 2.0.0
15-11-2018 12:36:27.303 [main] INFO  o.a.kafka.common.utils.AppInfoParser.<init> - Kafka commitId : 3402a8361b734732
15-11-2018 12:36:27.306 [main] INFO  o.s.s.c.ThreadPoolTaskScheduler.initialize - Initializing ExecutorService
15-11-2018 12:36:27.353 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.Metadata.update - Cluster ID: P9qNm97PQxmUwOTGinTT9g
15-11-2018 12:36:27.360 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.onSuccess - [Consumer clientId=consumer-2, groupId=group_id6] Discovered group coordinator 172.23.239.131:9092 (id: 2147482646 rack: null)
15-11-2018 12:36:27.372 [main] INFO  o.s.b.w.e.tomcat.TomcatWebServer.start - Tomcat started on port(s): 8080 (http) with context path ''
15-11-2018 12:36:27.375 [main] INFO  c.s.c.ChallengeCreatorApplication.logStarted - Started ChallengeCreatorApplication in 11.058 seconds (JVM running for 12.77)
15-11-2018 12:36:27.379 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator.onJoinPrepare - [Consumer clientId=consumer-2, groupId=group_id6] Revoking previously assigned partitions []
15-11-2018 12:36:27.379 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer.onPartitionsRevoked - partitions revoked: []
15-11-2018 12:36:27.379 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.sendJoinGroupRequest - [Consumer clientId=consumer-2, groupId=group_id6] (Re-)joining group
15-11-2018 12:36:28.122 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.onSuccess - [Consumer clientId=consumer-2, groupId=group_id6] Successfully joined group with generation 9
15-11-2018 12:36:28.127 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator.onJoinComplete - [Consumer clientId=consumer-2, groupId=group_id6] Setting newly assigned partitions [test-challenge-0]
15-11-2018 12:36:28.144 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer.onPartitionsAssigned - partitions assigned: [test-challenge-0]
15-11-2018 12:36:56.376 [http-nio-8080-exec-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/].log - Initializing Spring DispatcherServlet 'dispatcherServlet'
15-11-2018 12:36:56.703 [http-nio-8080-exec-1] INFO  org.mongodb.driver.connection.info - Opened connection [connectionId{localValue:2, serverValue:11}] to localhost:27017
15-11-2018 12:36:56.861 [http-nio-8080-exec-1] INFO  o.a.k.c.producer.ProducerConfig.logAll - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [172.23.239.131:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

15-11-2018 12:36:56.884 [http-nio-8080-exec-1] INFO  o.a.kafka.common.utils.AppInfoParser.<init> - Kafka version : 2.0.0
15-11-2018 12:36:56.884 [http-nio-8080-exec-1] INFO  o.a.kafka.common.utils.AppInfoParser.<init> - Kafka commitId : 3402a8361b734732
15-11-2018 12:36:56.926 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata.update - Cluster ID: P9qNm97PQxmUwOTGinTT9g
15-11-2018 12:37:28.215 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.handle - [Consumer clientId=consumer-2, groupId=group_id6] Attempt to heartbeat failed since group is rebalancing
15-11-2018 12:37:28.221 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator.onJoinPrepare - [Consumer clientId=consumer-2, groupId=group_id6] Revoking previously assigned partitions [test-challenge-0]
15-11-2018 12:37:28.221 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer.onPartitionsRevoked - partitions revoked: [test-challenge-0]
15-11-2018 12:37:28.221 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.sendJoinGroupRequest - [Consumer clientId=consumer-2, groupId=group_id6] (Re-)joining group
15-11-2018 12:37:28.271 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.onSuccess - [Consumer clientId=consumer-2, groupId=group_id6] Successfully joined group with generation 10
15-11-2018 12:37:28.272 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator.onJoinComplete - [Consumer clientId=consumer-2, groupId=group_id6] Setting newly assigned partitions [test-challenge-0]
15-11-2018 12:37:28.276 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer.onPartitionsAssigned - partitions assigned: [test-challenge-0]
15-11-2018 12:37:40.300 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.handle - [Consumer clientId=consumer-2, groupId=group_id6] Attempt to heartbeat failed since group is rebalancing
15-11-2018 12:37:40.305 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator.onJoinPrepare - [Consumer clientId=consumer-2, groupId=group_id6] Revoking previously assigned partitions [test-challenge-0]
15-11-2018 12:37:40.305 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer.onPartitionsRevoked - partitions revoked: [test-challenge-0]
15-11-2018 12:37:40.305 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.sendJoinGroupRequest - [Consumer clientId=consumer-2, groupId=group_id6] (Re-)joining group
15-11-2018 12:37:40.357 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.onSuccess - [Consumer clientId=consumer-2, groupId=group_id6] Successfully joined group with generation 11
15-11-2018 12:37:40.358 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator.onJoinComplete - [Consumer clientId=consumer-2, groupId=group_id6] Setting newly assigned partitions [test-challenge-0]
15-11-2018 12:37:40.363 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer.onPartitionsAssigned - partitions assigned: [test-challenge-0]
15-11-2018 12:38:43.443 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.handle - [Consumer clientId=consumer-2, groupId=group_id6] Attempt to heartbeat failed since group is rebalancing
15-11-2018 12:38:43.448 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator.onJoinPrepare - [Consumer clientId=consumer-2, groupId=group_id6] Revoking previously assigned partitions [test-challenge-0]
15-11-2018 12:38:43.449 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer.onPartitionsRevoked - partitions revoked: [test-challenge-0]
15-11-2018 12:38:43.450 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.sendJoinGroupRequest - [Consumer clientId=consumer-2, groupId=group_id6] (Re-)joining group
15-11-2018 12:38:43.466 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.onSuccess - [Consumer clientId=consumer-2, groupId=group_id6] Successfully joined group with generation 12
15-11-2018 12:38:43.466 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator.onJoinComplete - [Consumer clientId=consumer-2, groupId=group_id6] Setting newly assigned partitions [test-challenge-0]
15-11-2018 12:38:43.472 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer.onPartitionsAssigned - partitions assigned: [test-challenge-0]
15-11-2018 12:38:49.478 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.handle - [Consumer clientId=consumer-2, groupId=group_id6] Attempt to heartbeat failed since group is rebalancing
15-11-2018 12:38:49.488 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator.onJoinPrepare - [Consumer clientId=consumer-2, groupId=group_id6] Revoking previously assigned partitions [test-challenge-0]
15-11-2018 12:38:49.489 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer.onPartitionsRevoked - partitions revoked: [test-challenge-0]
15-11-2018 12:38:49.489 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.sendJoinGroupRequest - [Consumer clientId=consumer-2, groupId=group_id6] (Re-)joining group
15-11-2018 12:38:49.500 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.onSuccess - [Consumer clientId=consumer-2, groupId=group_id6] Successfully joined group with generation 13
15-11-2018 12:38:49.501 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator.onJoinComplete - [Consumer clientId=consumer-2, groupId=group_id6] Setting newly assigned partitions [test-challenge-0]
15-11-2018 12:38:49.505 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer.onPartitionsAssigned - partitions assigned: [test-challenge-0]
15-11-2018 12:39:43.755 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.handle - [Consumer clientId=consumer-2, groupId=group_id6] Attempt to heartbeat failed since group is rebalancing
15-11-2018 12:39:43.792 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator.onJoinPrepare - [Consumer clientId=consumer-2, groupId=group_id6] Revoking previously assigned partitions [test-challenge-0]
15-11-2018 12:39:43.793 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer.onPartitionsRevoked - partitions revoked: [test-challenge-0]
15-11-2018 12:39:43.794 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.sendJoinGroupRequest - [Consumer clientId=consumer-2, groupId=group_id6] (Re-)joining group
15-11-2018 12:39:43.806 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.onSuccess - [Consumer clientId=consumer-2, groupId=group_id6] Successfully joined group with generation 14
15-11-2018 12:39:43.806 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator.onJoinComplete - [Consumer clientId=consumer-2, groupId=group_id6] Setting newly assigned partitions [test-challenge-0]
15-11-2018 12:39:43.859 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer.onPartitionsAssigned - partitions assigned: [test-challenge-0]
15-11-2018 12:39:45.264 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.s.c.ThreadPoolTaskScheduler.shutdown - Shutting down ExecutorService
15-11-2018 12:39:45.296 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer.run - Consumer stopped
15-11-2018 12:39:45.312 [Thread-2] INFO  o.s.s.c.ThreadPoolTaskExecutor.shutdown - Shutting down ExecutorService 'applicationTaskExecutor'
15-11-2018 12:39:45.315 [Thread-2] INFO  o.a.k.clients.producer.KafkaProducer.close - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
15-11-2018 12:39:45.321 [Thread-2] INFO  org.mongodb.driver.connection.info - Closed connection [connectionId{localValue:2, serverValue:11}] to localhost:27017 because the pool has been closed.
15-11-2018 12:39:54.869 [main] INFO  c.s.c.ChallengeCreatorApplication.logStarting - Starting ChallengeCreatorApplication on cgi-Latitude-E5440 with PID 9330 (/home/cgi/challenge-creator/target/classes started by cgi in /home/cgi/challenge-creator)
15-11-2018 12:39:54.902 [main] INFO  c.s.c.ChallengeCreatorApplication.logStartupProfileInfo - No active profile set, falling back to default profiles: default
15-11-2018 12:39:57.930 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate.registerRepositoriesIn - Bootstrapping Spring Data repositories in DEFAULT mode.
15-11-2018 12:39:58.176 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate.registerRepositoriesIn - Finished Spring Data repository scanning in 235ms. Found 5 repository interfaces.
15-11-2018 12:39:59.068 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker.postProcessAfterInitialization - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$a01dfd3a] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
15-11-2018 12:40:00.286 [main] INFO  o.s.b.w.e.tomcat.TomcatWebServer.initialize - Tomcat initialized with port(s): 8080 (http)
15-11-2018 12:40:00.320 [main] INFO  o.a.catalina.core.StandardService.log - Starting service [Tomcat]
15-11-2018 12:40:00.320 [main] INFO  o.a.catalina.core.StandardEngine.log - Starting Servlet Engine: Apache Tomcat/9.0.12
15-11-2018 12:40:00.335 [main] INFO  o.a.c.core.AprLifecycleListener.log - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib]
15-11-2018 12:40:00.465 [main] INFO  o.a.c.c.C.[Tomcat].[localhost].[/].log - Initializing Spring embedded WebApplicationContext
15-11-2018 12:40:00.517 [main] INFO  o.s.b.w.s.ServletRegistrationBean.addRegistration - Servlet dispatcherServlet mapped to [/]
15-11-2018 12:40:00.522 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'characterEncodingFilter' to: [/*]
15-11-2018 12:40:00.523 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
15-11-2018 12:40:00.524 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'formContentFilter' to: [/*]
15-11-2018 12:40:00.524 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'requestContextFilter' to: [/*]
15-11-2018 12:40:00.824 [main] INFO  org.mongodb.driver.cluster.info - Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
15-11-2018 12:40:00.891 [cluster-ClusterId{value='5bed1bc898d96e24726d227a', description='null'}-localhost:27017] INFO  org.mongodb.driver.connection.info - Opened connection [connectionId{localValue:1, serverValue:12}] to localhost:27017
15-11-2018 12:40:00.907 [cluster-ClusterId{value='5bed1bc898d96e24726d227a', description='null'}-localhost:27017] INFO  org.mongodb.driver.cluster.info - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 3]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=8940780}
15-11-2018 12:40:01.636 [main] INFO  o.s.s.c.ThreadPoolTaskExecutor.initialize - Initializing ExecutorService 'applicationTaskExecutor'
15-11-2018 12:40:01.939 [main] INFO  o.s.b.w.e.tomcat.TomcatWebServer.start - Tomcat started on port(s): 8080 (http) with context path ''
15-11-2018 12:40:01.944 [main] INFO  c.s.c.ChallengeCreatorApplication.logStarted - Started ChallengeCreatorApplication in 9.363 seconds (JVM running for 11.637)
15-11-2018 12:40:36.784 [http-nio-8080-exec-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/].log - Initializing Spring DispatcherServlet 'dispatcherServlet'
15-11-2018 12:40:37.370 [http-nio-8080-exec-1] INFO  org.mongodb.driver.connection.info - Opened connection [connectionId{localValue:2, serverValue:13}] to localhost:27017
15-11-2018 12:40:37.887 [http-nio-8080-exec-1] INFO  o.a.k.c.producer.ProducerConfig.logAll - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [172.23.239.131:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

15-11-2018 12:40:38.024 [http-nio-8080-exec-1] INFO  o.a.kafka.common.utils.AppInfoParser.<init> - Kafka version : 2.0.0
15-11-2018 12:40:38.025 [http-nio-8080-exec-1] INFO  o.a.kafka.common.utils.AppInfoParser.<init> - Kafka commitId : 3402a8361b734732
15-11-2018 12:40:38.718 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata.update - Cluster ID: P9qNm97PQxmUwOTGinTT9g
15-11-2018 12:41:01.091 [Thread-2] INFO  o.s.s.c.ThreadPoolTaskExecutor.shutdown - Shutting down ExecutorService 'applicationTaskExecutor'
15-11-2018 12:41:01.093 [Thread-2] INFO  o.a.k.clients.producer.KafkaProducer.close - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
15-11-2018 12:41:01.103 [Thread-2] INFO  org.mongodb.driver.connection.info - Closed connection [connectionId{localValue:2, serverValue:13}] to localhost:27017 because the pool has been closed.
15-11-2018 12:41:05.945 [main] INFO  c.s.c.ChallengeCreatorApplication.logStarting - Starting ChallengeCreatorApplication on cgi-Latitude-E5440 with PID 9726 (/home/cgi/challenge-creator/target/classes started by cgi in /home/cgi/challenge-creator)
15-11-2018 12:41:05.963 [main] INFO  c.s.c.ChallengeCreatorApplication.logStartupProfileInfo - No active profile set, falling back to default profiles: default
15-11-2018 12:41:07.265 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate.registerRepositoriesIn - Bootstrapping Spring Data repositories in DEFAULT mode.
15-11-2018 12:41:07.376 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate.registerRepositoriesIn - Finished Spring Data repository scanning in 103ms. Found 5 repository interfaces.
15-11-2018 12:41:07.747 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker.postProcessAfterInitialization - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$2977a9c] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
15-11-2018 12:41:08.304 [main] INFO  o.s.b.w.e.tomcat.TomcatWebServer.initialize - Tomcat initialized with port(s): 8080 (http)
15-11-2018 12:41:08.337 [main] INFO  o.a.catalina.core.StandardService.log - Starting service [Tomcat]
15-11-2018 12:41:08.337 [main] INFO  o.a.catalina.core.StandardEngine.log - Starting Servlet Engine: Apache Tomcat/9.0.12
15-11-2018 12:41:08.353 [main] INFO  o.a.c.core.AprLifecycleListener.log - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib]
15-11-2018 12:41:08.479 [main] INFO  o.a.c.c.C.[Tomcat].[localhost].[/].log - Initializing Spring embedded WebApplicationContext
15-11-2018 12:41:08.527 [main] INFO  o.s.b.w.s.ServletRegistrationBean.addRegistration - Servlet dispatcherServlet mapped to [/]
15-11-2018 12:41:08.533 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'characterEncodingFilter' to: [/*]
15-11-2018 12:41:08.534 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
15-11-2018 12:41:08.535 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'formContentFilter' to: [/*]
15-11-2018 12:41:08.535 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'requestContextFilter' to: [/*]
15-11-2018 12:41:08.847 [main] INFO  org.mongodb.driver.cluster.info - Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
15-11-2018 12:41:08.923 [cluster-ClusterId{value='5bed1c0c05a08325fe009d00', description='null'}-localhost:27017] INFO  org.mongodb.driver.connection.info - Opened connection [connectionId{localValue:1, serverValue:14}] to localhost:27017
15-11-2018 12:41:08.940 [cluster-ClusterId{value='5bed1c0c05a08325fe009d00', description='null'}-localhost:27017] INFO  org.mongodb.driver.cluster.info - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 3]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=3740317}
15-11-2018 12:41:09.755 [main] INFO  o.s.s.c.ThreadPoolTaskExecutor.initialize - Initializing ExecutorService 'applicationTaskExecutor'
15-11-2018 12:41:10.037 [main] INFO  o.a.k.c.consumer.ConsumerConfig.logAll - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [172.23.239.131:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.BytesDeserializer

15-11-2018 12:41:10.097 [main] INFO  o.a.kafka.common.utils.AppInfoParser.<init> - Kafka version : 2.0.0
15-11-2018 12:41:10.098 [main] INFO  o.a.kafka.common.utils.AppInfoParser.<init> - Kafka commitId : 3402a8361b734732
15-11-2018 12:41:10.208 [main] INFO  org.apache.kafka.clients.Metadata.update - Cluster ID: P9qNm97PQxmUwOTGinTT9g
15-11-2018 12:41:10.223 [main] INFO  o.a.k.c.consumer.ConsumerConfig.logAll - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [172.23.239.131:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.BytesDeserializer

15-11-2018 12:41:10.230 [main] INFO  o.a.kafka.common.utils.AppInfoParser.<init> - Kafka version : 2.0.0
15-11-2018 12:41:10.231 [main] INFO  o.a.kafka.common.utils.AppInfoParser.<init> - Kafka commitId : 3402a8361b734732
15-11-2018 12:41:10.234 [main] INFO  o.s.s.c.ThreadPoolTaskScheduler.initialize - Initializing ExecutorService
15-11-2018 12:41:10.277 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.Metadata.update - Cluster ID: P9qNm97PQxmUwOTGinTT9g
15-11-2018 12:41:10.278 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.onSuccess - [Consumer clientId=consumer-2, groupId=group_id6] Discovered group coordinator 172.23.239.131:9092 (id: 2147482646 rack: null)
15-11-2018 12:41:10.291 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator.onJoinPrepare - [Consumer clientId=consumer-2, groupId=group_id6] Revoking previously assigned partitions []
15-11-2018 12:41:10.292 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer.onPartitionsRevoked - partitions revoked: []
15-11-2018 12:41:10.292 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.sendJoinGroupRequest - [Consumer clientId=consumer-2, groupId=group_id6] (Re-)joining group
15-11-2018 12:41:10.355 [main] INFO  o.s.b.w.e.tomcat.TomcatWebServer.start - Tomcat started on port(s): 8080 (http) with context path ''
15-11-2018 12:41:10.366 [main] INFO  c.s.c.ChallengeCreatorApplication.logStarted - Started ChallengeCreatorApplication in 5.623 seconds (JVM running for 6.437)
15-11-2018 12:41:12.419 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.onSuccess - [Consumer clientId=consumer-2, groupId=group_id6] Successfully joined group with generation 17
15-11-2018 12:41:12.422 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator.onJoinComplete - [Consumer clientId=consumer-2, groupId=group_id6] Setting newly assigned partitions [test-challenge-0]
15-11-2018 12:41:12.429 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer.onPartitionsAssigned - partitions assigned: [test-challenge-0]
15-11-2018 12:41:26.816 [http-nio-8080-exec-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/].log - Initializing Spring DispatcherServlet 'dispatcherServlet'
15-11-2018 12:41:27.118 [http-nio-8080-exec-1] INFO  org.mongodb.driver.connection.info - Opened connection [connectionId{localValue:2, serverValue:15}] to localhost:27017
15-11-2018 12:41:27.269 [http-nio-8080-exec-1] INFO  o.a.k.c.producer.ProducerConfig.logAll - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [172.23.239.131:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

15-11-2018 12:41:27.295 [http-nio-8080-exec-1] INFO  o.a.kafka.common.utils.AppInfoParser.<init> - Kafka version : 2.0.0
15-11-2018 12:41:27.296 [http-nio-8080-exec-1] INFO  o.a.kafka.common.utils.AppInfoParser.<init> - Kafka commitId : 3402a8361b734732
15-11-2018 12:41:27.361 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata.update - Cluster ID: P9qNm97PQxmUwOTGinTT9g
15-11-2018 12:44:45.491 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.handle - [Consumer clientId=consumer-2, groupId=group_id6] Attempt to heartbeat failed since group is rebalancing
15-11-2018 12:44:45.497 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator.onJoinPrepare - [Consumer clientId=consumer-2, groupId=group_id6] Revoking previously assigned partitions [test-challenge-0]
15-11-2018 12:44:45.498 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer.onPartitionsRevoked - partitions revoked: [test-challenge-0]
15-11-2018 12:44:45.498 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.sendJoinGroupRequest - [Consumer clientId=consumer-2, groupId=group_id6] (Re-)joining group
15-11-2018 12:44:45.507 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.onSuccess - [Consumer clientId=consumer-2, groupId=group_id6] Successfully joined group with generation 18
15-11-2018 12:44:45.508 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator.onJoinComplete - [Consumer clientId=consumer-2, groupId=group_id6] Setting newly assigned partitions [test-challenge-0]
15-11-2018 12:44:45.511 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer.onPartitionsAssigned - partitions assigned: [test-challenge-0]
15-11-2018 12:47:22.232 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.s.c.ThreadPoolTaskScheduler.shutdown - Shutting down ExecutorService
15-11-2018 12:47:22.239 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer.run - Consumer stopped
15-11-2018 12:47:22.241 [Thread-2] INFO  o.s.s.c.ThreadPoolTaskExecutor.shutdown - Shutting down ExecutorService 'applicationTaskExecutor'
15-11-2018 12:47:22.242 [Thread-2] INFO  o.a.k.clients.producer.KafkaProducer.close - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
15-11-2018 12:47:22.247 [Thread-2] INFO  org.mongodb.driver.connection.info - Closed connection [connectionId{localValue:2, serverValue:15}] to localhost:27017 because the pool has been closed.
15-11-2018 15:39:25.897 [main] INFO  c.s.c.ChallengeCreatorApplication.logStarting - Starting ChallengeCreatorApplication on cgi-Latitude-E5440 with PID 15200 (/home/cgi/challenge-creator/target/classes started by cgi in /home/cgi/challenge-creator)
15-11-2018 15:39:25.924 [main] INFO  c.s.c.ChallengeCreatorApplication.logStartupProfileInfo - No active profile set, falling back to default profiles: default
15-11-2018 15:39:27.530 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate.registerRepositoriesIn - Bootstrapping Spring Data repositories in DEFAULT mode.
15-11-2018 15:39:27.633 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate.registerRepositoriesIn - Finished Spring Data repository scanning in 96ms. Found 5 repository interfaces.
15-11-2018 15:39:27.983 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker.postProcessAfterInitialization - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$71daf168] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
15-11-2018 15:39:28.554 [main] INFO  o.s.b.w.e.tomcat.TomcatWebServer.initialize - Tomcat initialized with port(s): 8080 (http)
15-11-2018 15:39:28.586 [main] INFO  o.a.catalina.core.StandardService.log - Starting service [Tomcat]
15-11-2018 15:39:28.587 [main] INFO  o.a.catalina.core.StandardEngine.log - Starting Servlet Engine: Apache Tomcat/9.0.12
15-11-2018 15:39:28.599 [main] INFO  o.a.c.core.AprLifecycleListener.log - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib]
15-11-2018 15:39:28.707 [main] INFO  o.a.c.c.C.[Tomcat].[localhost].[/].log - Initializing Spring embedded WebApplicationContext
15-11-2018 15:39:28.745 [main] INFO  o.s.b.w.s.ServletRegistrationBean.addRegistration - Servlet dispatcherServlet mapped to [/]
15-11-2018 15:39:28.750 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'characterEncodingFilter' to: [/*]
15-11-2018 15:39:28.751 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
15-11-2018 15:39:28.752 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'formContentFilter' to: [/*]
15-11-2018 15:39:28.753 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'requestContextFilter' to: [/*]
15-11-2018 15:39:29.480 [main] INFO  org.mongodb.driver.cluster.info - Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
15-11-2018 15:39:29.682 [cluster-ClusterId{value='5bed45d9a7a45b3b6018c1b4', description='null'}-localhost:27017] INFO  org.mongodb.driver.connection.info - Opened connection [connectionId{localValue:1, serverValue:16}] to localhost:27017
15-11-2018 15:39:29.693 [cluster-ClusterId{value='5bed45d9a7a45b3b6018c1b4', description='null'}-localhost:27017] INFO  org.mongodb.driver.cluster.info - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 3]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=7195499}
15-11-2018 15:39:30.429 [main] INFO  o.s.s.c.ThreadPoolTaskExecutor.initialize - Initializing ExecutorService 'applicationTaskExecutor'
15-11-2018 15:39:30.766 [main] INFO  o.a.k.c.consumer.ConsumerConfig.logAll - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [172.23.239.131:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.BytesDeserializer

15-11-2018 15:39:30.830 [main] INFO  o.a.kafka.common.utils.AppInfoParser.<init> - Kafka version : 2.0.0
15-11-2018 15:39:30.830 [main] INFO  o.a.kafka.common.utils.AppInfoParser.<init> - Kafka commitId : 3402a8361b734732
15-11-2018 15:39:49.233 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:39:52.399 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:39:55.471 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:39:58.543 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:40:01.615 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:40:04.687 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:40:07.759 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:40:10.831 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:40:13.903 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:40:16.975 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:40:20.047 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:40:23.119 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:40:26.191 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:40:29.263 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:40:30.914 [main] WARN  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext.refresh - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.context.ApplicationContextException: Failed to start bean 'org.springframework.kafka.config.internalKafkaListenerEndpointRegistry'; nested exception is org.apache.kafka.common.errors.TimeoutException: Timeout expired while fetching topic metadata
15-11-2018 15:40:30.915 [main] INFO  o.s.s.c.ThreadPoolTaskExecutor.shutdown - Shutting down ExecutorService 'applicationTaskExecutor'
15-11-2018 15:40:30.924 [main] INFO  o.a.catalina.core.StandardService.log - Stopping service [Tomcat]
15-11-2018 15:40:30.966 [main] INFO  o.s.b.a.l.ConditionEvaluationReportLoggingListener.logMessage - 

Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
15-11-2018 15:40:30.972 [main] ERROR o.s.boot.SpringApplication.reportFailure - Application run failed
org.springframework.context.ApplicationContextException: Failed to start bean 'org.springframework.kafka.config.internalKafkaListenerEndpointRegistry'; nested exception is org.apache.kafka.common.errors.TimeoutException: Timeout expired while fetching topic metadata
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:185)
	at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:53)
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:360)
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:158)
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:122)
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:879)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.finishRefresh(ServletWebServerApplicationContext.java:161)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:140)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:316)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248)
	at com.stackroute.challengecreator.ChallengeCreatorApplication.main(ChallengeCreatorApplication.java:10)
Caused by: org.apache.kafka.common.errors.TimeoutException: Timeout expired while fetching topic metadata
15-11-2018 15:40:55.594 [main] INFO  c.s.c.ChallengeCreatorApplicationTests.logStarting - Starting ChallengeCreatorApplicationTests on cgi-Latitude-E5440 with PID 15900 (started by cgi in /home/cgi/challenge-creator)
15-11-2018 15:40:55.600 [main] INFO  c.s.c.ChallengeCreatorApplicationTests.logStartupProfileInfo - No active profile set, falling back to default profiles: default
15-11-2018 15:40:56.697 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate.registerRepositoriesIn - Bootstrapping Spring Data repositories in DEFAULT mode.
15-11-2018 15:40:56.807 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate.registerRepositoriesIn - Finished Spring Data repository scanning in 102ms. Found 5 repository interfaces.
15-11-2018 15:40:57.239 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker.postProcessAfterInitialization - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$f5e30d44] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
15-11-2018 15:40:57.659 [main] INFO  org.mongodb.driver.cluster.info - Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
15-11-2018 15:40:57.763 [cluster-ClusterId{value='5bed4631928bbd3e1c5c8191', description='null'}-localhost:27017] INFO  org.mongodb.driver.connection.info - Opened connection [connectionId{localValue:1, serverValue:17}] to localhost:27017
15-11-2018 15:40:57.771 [cluster-ClusterId{value='5bed4631928bbd3e1c5c8191', description='null'}-localhost:27017] INFO  org.mongodb.driver.cluster.info - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 3]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=3622317}
15-11-2018 15:40:59.381 [main] INFO  o.s.s.c.ThreadPoolTaskExecutor.initialize - Initializing ExecutorService 'applicationTaskExecutor'
15-11-2018 15:40:59.974 [main] INFO  o.a.k.c.consumer.ConsumerConfig.logAll - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [172.23.239.131:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.BytesDeserializer

15-11-2018 15:41:00.072 [main] INFO  o.a.kafka.common.utils.AppInfoParser.<init> - Kafka version : 2.0.0
15-11-2018 15:41:00.073 [main] INFO  o.a.kafka.common.utils.AppInfoParser.<init> - Kafka commitId : 3402a8361b734732
15-11-2018 15:41:03.282 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:41:06.355 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:41:09.423 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:41:12.495 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:41:15.567 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:41:18.639 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:41:21.711 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:41:24.783 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:41:27.855 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:41:30.927 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:41:33.999 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:41:37.071 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:41:40.143 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:41:43.215 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:41:46.287 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:41:49.359 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:41:52.431 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:41:55.503 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:41:58.575 [main] WARN  o.apache.kafka.clients.NetworkClient.processDisconnection - [Consumer clientId=consumer-1, groupId=group_id6] Connection to node -1 could not be established. Broker may not be available.
15-11-2018 15:41:59.718 [main] INFO  org.apache.kafka.clients.Metadata.update - Cluster ID: P9qNm97PQxmUwOTGinTT9g
15-11-2018 15:41:59.743 [main] INFO  o.a.k.c.consumer.ConsumerConfig.logAll - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [172.23.239.131:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.BytesDeserializer

15-11-2018 15:41:59.751 [main] INFO  o.a.kafka.common.utils.AppInfoParser.<init> - Kafka version : 2.0.0
15-11-2018 15:41:59.751 [main] INFO  o.a.kafka.common.utils.AppInfoParser.<init> - Kafka commitId : 3402a8361b734732
15-11-2018 15:41:59.754 [main] INFO  o.s.s.c.ThreadPoolTaskScheduler.initialize - Initializing ExecutorService
15-11-2018 15:41:59.796 [main] INFO  c.s.c.ChallengeCreatorApplicationTests.logStarted - Started ChallengeCreatorApplicationTests in 64.741 seconds (JVM running for 66.057)
15-11-2018 15:41:59.808 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.Metadata.update - Cluster ID: P9qNm97PQxmUwOTGinTT9g
15-11-2018 15:41:59.809 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.onSuccess - [Consumer clientId=consumer-2, groupId=group_id6] Discovered group coordinator 172.23.239.131:9092 (id: 2147482646 rack: null)
15-11-2018 15:41:59.829 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator.onJoinPrepare - [Consumer clientId=consumer-2, groupId=group_id6] Revoking previously assigned partitions []
15-11-2018 15:41:59.830 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer.onPartitionsRevoked - partitions revoked: []
15-11-2018 15:41:59.830 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.sendJoinGroupRequest - [Consumer clientId=consumer-2, groupId=group_id6] (Re-)joining group
15-11-2018 15:41:59.891 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.onSuccess - [Consumer clientId=consumer-2, groupId=group_id6] Successfully joined group with generation 20
15-11-2018 15:41:59.895 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator.onJoinComplete - [Consumer clientId=consumer-2, groupId=group_id6] Setting newly assigned partitions [test-challenge-0]
15-11-2018 15:41:59.921 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer.onPartitionsAssigned - partitions assigned: [test-challenge-0]
15-11-2018 15:42:01.171 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.s.c.ThreadPoolTaskScheduler.shutdown - Shutting down ExecutorService
15-11-2018 15:42:01.201 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer.run - Consumer stopped
15-11-2018 15:42:01.211 [Thread-1] INFO  o.s.s.c.ThreadPoolTaskExecutor.shutdown - Shutting down ExecutorService 'applicationTaskExecutor'
15-11-2018 15:42:30.848 [main] INFO  c.s.c.ChallengeCreatorApplication.logStarting - Starting ChallengeCreatorApplication on cgi-Latitude-E5440 with PID 16617 (/home/cgi/challenge-creator/target/classes started by cgi in /home/cgi/challenge-creator)
15-11-2018 15:42:30.857 [main] INFO  c.s.c.ChallengeCreatorApplication.logStartupProfileInfo - No active profile set, falling back to default profiles: default
15-11-2018 15:42:32.418 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate.registerRepositoriesIn - Bootstrapping Spring Data repositories in DEFAULT mode.
15-11-2018 15:42:32.522 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate.registerRepositoriesIn - Finished Spring Data repository scanning in 97ms. Found 5 repository interfaces.
15-11-2018 15:42:32.888 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker.postProcessAfterInitialization - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$a0e933ee] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
15-11-2018 15:42:33.461 [main] INFO  o.s.b.w.e.tomcat.TomcatWebServer.initialize - Tomcat initialized with port(s): 8080 (http)
15-11-2018 15:42:33.493 [main] INFO  o.a.catalina.core.StandardService.log - Starting service [Tomcat]
15-11-2018 15:42:33.493 [main] INFO  o.a.catalina.core.StandardEngine.log - Starting Servlet Engine: Apache Tomcat/9.0.12
15-11-2018 15:42:33.508 [main] INFO  o.a.c.core.AprLifecycleListener.log - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib]
15-11-2018 15:42:33.627 [main] INFO  o.a.c.c.C.[Tomcat].[localhost].[/].log - Initializing Spring embedded WebApplicationContext
15-11-2018 15:42:33.664 [main] INFO  o.s.b.w.s.ServletRegistrationBean.addRegistration - Servlet dispatcherServlet mapped to [/]
15-11-2018 15:42:33.670 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'characterEncodingFilter' to: [/*]
15-11-2018 15:42:33.671 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
15-11-2018 15:42:33.672 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'formContentFilter' to: [/*]
15-11-2018 15:42:33.673 [main] INFO  o.s.b.w.s.FilterRegistrationBean.configure - Mapping filter: 'requestContextFilter' to: [/*]
15-11-2018 15:42:33.981 [main] INFO  org.mongodb.driver.cluster.info - Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
15-11-2018 15:42:34.082 [cluster-ClusterId{value='5bed4691e3800040e99ed451', description='null'}-localhost:27017] INFO  org.mongodb.driver.connection.info - Opened connection [connectionId{localValue:1, serverValue:18}] to localhost:27017
15-11-2018 15:42:34.097 [cluster-ClusterId{value='5bed4691e3800040e99ed451', description='null'}-localhost:27017] INFO  org.mongodb.driver.cluster.info - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 3]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=3385024}
15-11-2018 15:42:34.817 [main] INFO  o.s.s.c.ThreadPoolTaskExecutor.initialize - Initializing ExecutorService 'applicationTaskExecutor'
15-11-2018 15:42:35.134 [main] INFO  o.a.k.c.consumer.ConsumerConfig.logAll - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [172.23.239.131:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.BytesDeserializer

15-11-2018 15:42:35.194 [main] INFO  o.a.kafka.common.utils.AppInfoParser.<init> - Kafka version : 2.0.0
15-11-2018 15:42:35.194 [main] INFO  o.a.kafka.common.utils.AppInfoParser.<init> - Kafka commitId : 3402a8361b734732
15-11-2018 15:42:35.395 [main] INFO  org.apache.kafka.clients.Metadata.update - Cluster ID: P9qNm97PQxmUwOTGinTT9g
15-11-2018 15:42:35.412 [main] INFO  o.a.k.c.consumer.ConsumerConfig.logAll - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [172.23.239.131:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.BytesDeserializer

15-11-2018 15:42:35.420 [main] INFO  o.a.kafka.common.utils.AppInfoParser.<init> - Kafka version : 2.0.0
15-11-2018 15:42:35.421 [main] INFO  o.a.kafka.common.utils.AppInfoParser.<init> - Kafka commitId : 3402a8361b734732
15-11-2018 15:42:35.424 [main] INFO  o.s.s.c.ThreadPoolTaskScheduler.initialize - Initializing ExecutorService
15-11-2018 15:42:35.481 [main] INFO  o.s.b.w.e.tomcat.TomcatWebServer.start - Tomcat started on port(s): 8080 (http) with context path ''
15-11-2018 15:42:35.485 [main] INFO  c.s.c.ChallengeCreatorApplication.logStarted - Started ChallengeCreatorApplication in 5.591 seconds (JVM running for 6.438)
15-11-2018 15:42:35.530 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.Metadata.update - Cluster ID: P9qNm97PQxmUwOTGinTT9g
15-11-2018 15:42:35.531 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.onSuccess - [Consumer clientId=consumer-2, groupId=group_id6] Discovered group coordinator 172.23.239.131:9092 (id: 2147482646 rack: null)
15-11-2018 15:42:35.533 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator.onJoinPrepare - [Consumer clientId=consumer-2, groupId=group_id6] Revoking previously assigned partitions []
15-11-2018 15:42:35.534 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer.onPartitionsRevoked - partitions revoked: []
15-11-2018 15:42:35.534 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.sendJoinGroupRequest - [Consumer clientId=consumer-2, groupId=group_id6] (Re-)joining group
15-11-2018 15:42:35.568 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.onSuccess - [Consumer clientId=consumer-2, groupId=group_id6] Successfully joined group with generation 22
15-11-2018 15:42:35.574 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator.onJoinComplete - [Consumer clientId=consumer-2, groupId=group_id6] Setting newly assigned partitions [test-challenge-0]
15-11-2018 15:42:35.623 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer.onPartitionsAssigned - partitions assigned: [test-challenge-0]
15-11-2018 15:44:02.693 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.s.c.ThreadPoolTaskScheduler.shutdown - Shutting down ExecutorService
15-11-2018 15:44:02.704 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer.run - Consumer stopped
15-11-2018 15:44:02.710 [Thread-2] INFO  o.s.s.c.ThreadPoolTaskExecutor.shutdown - Shutting down ExecutorService 'applicationTaskExecutor'
15-11-2018 15:55:12.175 [main] INFO  c.s.c.ChallengeCreatorApplicationTests.logStarting - Starting ChallengeCreatorApplicationTests on cgi-Latitude-E5440 with PID 22015 (started by cgi in /home/cgi/challenge-creator)
15-11-2018 15:55:12.178 [main] INFO  c.s.c.ChallengeCreatorApplicationTests.logStartupProfileInfo - No active profile set, falling back to default profiles: default
15-11-2018 15:55:13.173 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate.registerRepositoriesIn - Bootstrapping Spring Data repositories in DEFAULT mode.
15-11-2018 15:55:13.275 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate.registerRepositoriesIn - Finished Spring Data repository scanning in 94ms. Found 5 repository interfaces.
15-11-2018 15:55:13.710 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker.postProcessAfterInitialization - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$d24828ce] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
15-11-2018 15:55:14.079 [main] INFO  org.mongodb.driver.cluster.info - Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
15-11-2018 15:55:14.184 [cluster-ClusterId{value='5bed498ade56c155ff03d838', description='null'}-localhost:27017] INFO  org.mongodb.driver.connection.info - Opened connection [connectionId{localValue:1, serverValue:19}] to localhost:27017
15-11-2018 15:55:14.195 [cluster-ClusterId{value='5bed498ade56c155ff03d838', description='null'}-localhost:27017] INFO  org.mongodb.driver.cluster.info - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 3]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=4062327}
15-11-2018 15:55:15.470 [main] INFO  o.s.s.c.ThreadPoolTaskExecutor.initialize - Initializing ExecutorService 'applicationTaskExecutor'
15-11-2018 15:55:15.947 [main] INFO  o.a.k.c.consumer.ConsumerConfig.logAll - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [172.23.239.131:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.BytesDeserializer

15-11-2018 15:55:16.096 [main] INFO  o.a.kafka.common.utils.AppInfoParser.<init> - Kafka version : 2.0.0
15-11-2018 15:55:16.097 [main] INFO  o.a.kafka.common.utils.AppInfoParser.<init> - Kafka commitId : 3402a8361b734732
15-11-2018 15:55:16.241 [main] INFO  org.apache.kafka.clients.Metadata.update - Cluster ID: P9qNm97PQxmUwOTGinTT9g
15-11-2018 15:55:16.258 [main] INFO  o.a.k.c.consumer.ConsumerConfig.logAll - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [172.23.239.131:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.BytesDeserializer

15-11-2018 15:55:16.266 [main] INFO  o.a.kafka.common.utils.AppInfoParser.<init> - Kafka version : 2.0.0
15-11-2018 15:55:16.267 [main] INFO  o.a.kafka.common.utils.AppInfoParser.<init> - Kafka commitId : 3402a8361b734732
15-11-2018 15:55:16.270 [main] INFO  o.s.s.c.ThreadPoolTaskScheduler.initialize - Initializing ExecutorService
15-11-2018 15:55:16.324 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.Metadata.update - Cluster ID: P9qNm97PQxmUwOTGinTT9g
15-11-2018 15:55:16.326 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.onSuccess - [Consumer clientId=consumer-2, groupId=group_id6] Discovered group coordinator 172.23.239.131:9092 (id: 2147482646 rack: null)
15-11-2018 15:55:16.322 [main] INFO  c.s.c.ChallengeCreatorApplicationTests.logStarted - Started ChallengeCreatorApplicationTests in 4.629 seconds (JVM running for 5.817)
15-11-2018 15:55:16.361 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator.onJoinPrepare - [Consumer clientId=consumer-2, groupId=group_id6] Revoking previously assigned partitions []
15-11-2018 15:55:16.362 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer.onPartitionsRevoked - partitions revoked: []
15-11-2018 15:55:16.362 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.sendJoinGroupRequest - [Consumer clientId=consumer-2, groupId=group_id6] (Re-)joining group
15-11-2018 15:55:16.388 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.AbstractCoordinator.onSuccess - [Consumer clientId=consumer-2, groupId=group_id6] Successfully joined group with generation 24
15-11-2018 15:55:16.392 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.c.i.ConsumerCoordinator.onJoinComplete - [Consumer clientId=consumer-2, groupId=group_id6] Setting newly assigned partitions [test-challenge-0]
15-11-2018 15:55:16.400 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer.onPartitionsAssigned - partitions assigned: [test-challenge-0]
15-11-2018 15:55:16.810 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.s.c.ThreadPoolTaskScheduler.shutdown - Shutting down ExecutorService
15-11-2018 15:55:16.834 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer.run - Consumer stopped
15-11-2018 15:55:16.846 [Thread-1] INFO  o.s.s.c.ThreadPoolTaskExecutor.shutdown - Shutting down ExecutorService 'applicationTaskExecutor'
